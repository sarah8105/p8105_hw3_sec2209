P8105 Homework 3
================
sarah\_8105

This is my third homework assignment for P8105.

``` r
library(tidyverse)
```

    ## -- Attaching packages ---------------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(p8105.datasets)
```

## Problem 1

In this first problem, I explore the Instacart data. I create a plot of
the number of items ordered in each aisle, limiting to aisles with more
than 10,000 items ordered.

``` r
data("instacart")
```

Next, I create a table that displays the three most population items in
each of the aisles of “baking ingredients”, “dog food care”, and
“packaged vegetables fruits”. The table displays the number of times
each item was ordered.

In the final portion of problem 1, I create a table that shows the mean
hour of the day at which Pink Lady apples and coffee ice cream are
ordered on each day of the week.

The Instacart data contain de-identified grocery orders for users of
this online grocery service, which partners with local stores like Whole
Foods and Fairway to deliver groceries within 2 hours of order. Each row
in the data set represents a product that has been ordered. The data
include variables about the order (such as date and time), the customer,
and about the products ordered (such as product name and
department/aisle where the product can be found).

There are a total of `r` orders, `r` customers, and `r` products
represented in these data. On average, customers have placed `r` orders
and each order contains `r` products.

There are `r` aisles represented in the data. Most items that are
ordered come from the `r` aisle, with `r` items ordered. The most
popular item from the baking ingredients aisle was `r`, the most
population item from the dog food care aisle was `r`, and the most
population item from the packaged vegetables fruits aisle was `r`.

## Problem 2

In this code chunk, I load and tidy the accelerometer data. I use the
`clean_names()` function from the `janitor` package to clean the
variable names, create a weekday versus weekend variable, and encode
data with reasonable variable classes.

``` r
accel = 
  read_csv(
    "./Data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_count",
    values_to = "active",
    names_prefix = "activity_"
  ) %>%
  mutate(weekend = ifelse(day_id %in% c(3, 4), "Weekend", "Weekday"))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

The resulting data set contains 50400 rows and 6 variables. This data
set contains indicator variables for the week number (`week`) and day of
the week (`day`), a variable `activity_count` that represents
incremental one-minute measurement interval of the accelerometer, a
variable that represents the accelerometer reading (`active`) and the
`weekend` indicator that defines whether it was a weekend or weekday.

In the next code chunk, I aggregate the activity totals for each day and
display the data in a table.

``` r
accel %>%
  group_by(week, day) %>%
  summarize(
    total_Active = sum(active)) %>% 
  knitr::kable(digits = 1)
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

| week | day       | total\_Active |
| ---: | :-------- | ------------: |
|    1 | Friday    |      480542.6 |
|    1 | Monday    |       78828.1 |
|    1 | Saturday  |      376254.0 |
|    1 | Sunday    |      631105.0 |
|    1 | Thursday  |      355923.6 |
|    1 | Tuesday   |      307094.2 |
|    1 | Wednesday |      340115.0 |
|    2 | Friday    |      568839.0 |
|    2 | Monday    |      295431.0 |
|    2 | Saturday  |      607175.0 |
|    2 | Sunday    |      422018.0 |
|    2 | Thursday  |      474048.0 |
|    2 | Tuesday   |      423245.0 |
|    2 | Wednesday |      440962.0 |
|    3 | Friday    |      467420.0 |
|    3 | Monday    |      685910.0 |
|    3 | Saturday  |      382928.0 |
|    3 | Sunday    |      467052.0 |
|    3 | Thursday  |      371230.0 |
|    3 | Tuesday   |      381507.0 |
|    3 | Wednesday |      468869.0 |
|    4 | Friday    |      154049.0 |
|    4 | Monday    |      409450.0 |
|    4 | Saturday  |        1440.0 |
|    4 | Sunday    |      260617.0 |
|    4 | Thursday  |      340291.0 |
|    4 | Tuesday   |      319568.0 |
|    4 | Wednesday |      434460.0 |
|    5 | Friday    |      620860.0 |
|    5 | Monday    |      389080.0 |
|    5 | Saturday  |        1440.0 |
|    5 | Sunday    |      138421.0 |
|    5 | Thursday  |      549658.0 |
|    5 | Tuesday   |      367824.0 |
|    5 | Wednesday |      445366.0 |

From this table, there appears to be a bit of a decline in activity on
the weekends.
